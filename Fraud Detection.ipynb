<a href="https://colab.research.google.com/github/aserravalle/Fraud-Detection-Logistic-Regression/blob/master/Fraud_Detection_Logistic_Regression.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
# Setup
## Kaggle
# Run this cell and select the kaggle.json file downloaded
# from the Kaggle account settings page.
from google.colab import files
files.upload()
# The Kaggle API client expects this file to be in ~/.kaggle, so move it there.
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

# This permissions change avoids a warning on Kaggle tool startup.
!chmod 600 ~/.kaggle/kaggle.json
! kaggle competitions download -c ieee-fraud-detection
## Dependencies
! pip install kmeans_smote 
import pandas as pd
import numpy as np
from datetime import datetime
from math import ceil

# Plotting
import matplotlib.pyplot as plt
plt.style.use('dark_background')

# Dimensionality reduction and SMOTE
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from kmeans_smote import KMeansSMOTE

# Model Evaluation
from sklearn.model_selection import train_test_split
from sklearn.metrics import recall_score
from sklearn.metrics import roc_curve, auc, roc_auc_score

# Modelling
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV

# Options
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
import warnings
warnings.filterwarnings("ignore")

# Target variable = 'isFraud'
## Reading Files
train_id = pd.read_csv('/content/train_identity.csv.zip', nrows=20000)
print(train_id.shape)
test_id = pd.read_csv('/content/test_identity.csv.zip', nrows=20000)
print(test_id.shape)
train_id.head()
train_trans = pd.read_csv('/content/train_transaction.csv.zip', nrows=20000)
print(train_trans.shape)
test_trans = pd.read_csv('/content/test_transaction.csv.zip', nrows=20000)
print(test_trans.shape)

train_trans.head()
# Cleaning
## Define fctn
def Clean(df):
    # Drop columns w many missing values
    thresh = ceil(len(df) * 0.4)
    cols = df.columns[df.isnull().sum() > thresh]
    df.drop(cols, axis = 1, inplace = True)
    print('DROP: ', [f+',' for f in cols])

    # Determine types of features
    cat_features = [f for f in df.columns if (np.dtype(df[f]) == 'object') & (f != 'TransactionID')]
    num_features = [f for f in df.columns if (np.dtype(df[f]) != 'object') & (f != 'TransactionID')]

    # Impute missing
    df2 = pd.DataFrame()
    df2[num_features] = df[num_features].fillna(df[num_features].mean())
    print('IMPUTE: ', [f+',' for f in cols])

    # OHE categorical
    for f in cat_features:
        dummies = pd.get_dummies(df[f], prefix = f, prefix_sep = ': ', dummy_na = True)
        df2 = pd.concat([df2, dummies], axis = 1)
    print('OHE: ', [f+',' for f in cat_features])

    # Get the ID back
    df2['TransactionID'] = df['TransactionID']
    print('Cleaned\n')
    return df2
train_id_clean = Clean(train_id)
test_id_clean = Clean(test_id)
train_trans_clean = Clean(train_trans)
test_trans_clean = Clean(test_trans)
## Remove Cols
that are not in both training and testing data
# Get a set of the columns in each dataframe
a = set(train_id_clean.columns)
print('train',len(a))
b = set(test_id_clean.columns)
print('test',len(b))

# Take the intersection
cols = list(a.intersection(b))
print('columns',len(cols))

# Set columns for both data frames equal to the set 
train_id_eql = train_id_clean.loc[:,cols]
test_id_eql = test_id_clean.loc[:,cols]

print('new train ',len(train_id_eql.columns))
print('new test ',len(test_id_eql.columns))
# Get a set of the columns in each dataframe
a = set(train_trans_clean.columns)
print('train',len(a))
b = set(test_trans_clean.columns)
print('test',len(b))

# Take the intersection
cols = list(a.intersection(b))
print('columns',len(cols))

# Set columns for both data frames equal to the set 
train_trans_eql = train_trans_clean.loc[:,cols] 
train_trans_eql['isFraud'] = train_trans_clean['isFraud'] # Remember to keep the target variable
test_trans_eql = test_trans_clean.loc[:,cols]

print('new train ',len(train_trans_eql.columns))
print('new test ',len(test_trans_eql.columns), '(missing isFraud)')
print(train_id_eql.shape)
print(test_id_eql.shape)
print(train_trans_eql.shape)
print(test_trans_eql.shape)
## Merge datasets
print(train_id_eql.shape, train_trans_eql.shape)

train_clean = train_trans_eql.merge(  train_id_eql, on = 'TransactionID', how = 'outer')
test_clean  =  test_trans_eql.merge(  test_id_eql , on = 'TransactionID', how = 'outer')

print(train_clean.shape)
# Fill with mean if missing
def DestroyMissing(df):
  df.fillna(df.mean(), inplace = True)
  df.fillna(df.mean(), inplace = True)


print(train_clean.shape)
train_clean.dropna(subset=['isFraud'], inplace=True)
DestroyMissing(train_clean)
print(train_clean.shape)

DestroyMissing(test_clean)
print(test_clean.shape)
## Saving clean files
train_clean.to_csv('/content/clean_train.csv', index = False)
print('/content/clean_train.csv')
test_clean.to_csv('/content/clean_test.csv', index = False)
print('/content/clean_test.csv')
# Dimension Reduction by Principal Component Analysis
## Training Data and Validation
# Standardise the X variables
def Standardise(X):
  X_Std = StandardScaler().fit_transform(X)
  X_Std = pd.DataFrame(X_Std, columns = X.columns)
  return X_Std

# Output PCA dataset
def PCA_DF(n_components, DF):
  pca = PCA(n_components)
  PrincComp = pca.fit_transform(DF)
  return pd.DataFrame(data = PrincComp)


# Evaluate recall of different PCAs to determine the best accuracy/computation tradeoff
def TestPCA(X_Std, y, a,b,c):
    LR = LogisticRegression()
    Eval = {'PCs':[], 'Recall':[]}
    X_Train, X_Test, Y_Train, Y_Test = train_test_split(X_Std, y, test_size=0.3)
    
    for PCs in range(a,b,c):
        print(PCs)
        
        # Create PCA dataframe
        Train_principalDf = PCA_DF(PCs, X_Train)
        Test_principalDf = PCA_DF(PCs, X_Test)
        
        # Use to train Logistic Regression model
        LR.fit(Train_principalDf, Y_Train)
        predictions = LR.predict(Test_principalDf)

        #Evaluate the model
        recall = recall_score(predictions, Y_Test)
        Eval['PCs'].append(PCs)
        Eval['Recall'].append(recall)

    # Return the recall scores for each number of PCs
    return pd.DataFrame(Eval['Recall'], index = Eval['PCs'])
train = pd.read_csv('/content/clean_train.csv')

# Separate predictors, target, and ID
ID = train[['TransactionID']]
X = train.drop('TransactionID', axis = 1)
y = train[['isFraud']]

# Output standardised dataset
X_Std = Standardise(X)
X_Std.head()
#scores = TestPCA(X_Std, y, 90,200, 20)
#plt.plot(scores)

# Best PCA value is around 125
# Determine 125 PCA Variables is a good balance between accuracy and computation time
train_PCA = PCA_DF(125, X_Std)
train_PCA['TransactionID'] = ID
train_PCA['isFraud'] = y

train_PCA.to_csv('PCA_train.csv',  index = False)

print('Training Data has been cleaned and saved')
## Test Data
test = pd.read_csv('/content/clean_test.csv')

# Process Testing data, same as training
X_Std_Test = Standardise(test.drop('TransactionID', axis =1 ))

# Confirm the shapes are as they should be
a = {'StdTest ': X_Std_Test,
     'OrgTest ': test,
     'StdTrain': X_Std,
     'OrgTrain':X}

for i in a.keys():
    print(i, a[i].shape)

X_Std_Test.head()
test_PCA = PCA_DF(125, X_Std_Test)
test_PCA['TransactionID'] = test['TransactionID']
test_PCA.to_csv('TEST.csv',  index = False)

print('Testing Data has been cleaned and saved')
# SMOTE
# train = pd.read_csv('/content/PCA_train.csv')

# Separate predictors, target, and ID
ID = train[['TransactionID']]
X = train.drop('TransactionID', axis = 1)
y = train[['isFraud']]

# Show the counts of each outcome
[print('Class {} has {} instances'.format(label, count))
 for label, count in zip(*np.unique(y, return_counts=True))]
# Fit SMOTE
kmeans_smote = KMeansSMOTE(kmeans_args={'n_clusters': 100},
                           smote_args={'k_neighbors': 10})
X_resampled, y_resampled = kmeans_smote.fit_sample(X, y)

[print('Class {} has {} instances after oversampling'.format(label, count))
 for label, count in zip(*np.unique(y_resampled, return_counts=True))]
X_resampled, y_resampled = pd.DataFrame(X_resampled), pd.DataFrame(y_resampled)

X_resampled.columns = X.columns
y_resampled.columns = ['y']

train_resampled = pd.concat([X_resampled,y_resampled, ID], axis = 1)
print(train_resampled.shape)
train_resampled.head()
## Save Resampled data
train_resampled.to_csv('TRAIN.csv',  index = False)
# Modelling
train = pd.read_csv('/content/TRAIN.csv')
print(train.shape)
test = pd.read_csv('/content/TEST.csv')
print(test.shape)
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
ID = train[['TransactionID']]
X = train.drop(['TransactionID', 'isFraud'], axis = 1)
y = train[['isFraud']]

clf = LogisticRegressionCV(cv=5, random_state=0).fit(X, y)

# Dictionary --> {isFraud: [Fold][Cs]}
# Test with training observations
xobs = pd.Series(X.loc[1,:])
clf.predict([xobs])
# Evaluation
# Evaluate model on training data
sub = ID
sub['True'] = y
sub['Pred'] = clf.predict(X)

# Accuracy
accuracy = np.where(sub['Pred'] == sub['True'], 1, 0)
print('Accuracy =', sum(accuracy)/ len(accuracy))

# Recall
TP = np.where((sub['Pred'] == sub['True']) & (sub['True'] == 1), 1, 0)
FN = np.where((sub['Pred'] != sub['True']) & (sub['True'] == 1), 1, 0)
print('Recall =', sum(TP)/ (sum(TP) + sum(FN)))

sub.head()
